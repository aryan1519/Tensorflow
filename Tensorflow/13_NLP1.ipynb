{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13_NLP1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FHC2juM7Xep"
      },
      "source": [
        "### Loading the data and making the training and validation sets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prTM2UbfomDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9dcff8c-fc0e-447c-ad7d-cfbfe6f75d20"
      },
      "source": [
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-05 19:46:54--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 74.125.195.128, 142.250.99.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2021-06-05 19:46:54 (135 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsNyvRsFwwG0"
      },
      "source": [
        "# The dataset is Natural Language Processing with Disaster Tweets from Kaggle.\n",
        "# If the above link is not available download zip from kaggle."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mLf5Vk3xssb",
        "outputId": "6106d12e-2f4a-471c-dc8b-31229e50e89e"
      },
      "source": [
        "!unzip \"/content/nlp_getting_started.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/nlp_getting_started.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBPsM5vyxvl-"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvTcHvAIyv2M"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/train.csv\")\n",
        "\n",
        "test_df = pd.read_csv(\"/content/test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "N5I3x5-kzBV1",
        "outputId": "c1c11582-9f41-4b57-a72f-c2c7674bab00"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "akFLCzZhzF5l",
        "outputId": "c7083a9f-810f-447c-f7d6-60b2eb02b40b"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cpJsA8ozJoC",
        "outputId": "d61a8c20-29b1-4888-e513-923fef359fba"
      },
      "source": [
        "print(train_df[\"text\"][45])\n",
        "print(train_df[\"target\"][45])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I gained 3 followers in the last week. You? Know your stats and grow with http://t.co/TIyUliF5c6\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ckX64y_zQJq",
        "outputId": "d61ad3bf-eba4-4e8e-ed38-2c887f0f2175"
      },
      "source": [
        "print(train_df[\"text\"][50])\n",
        "print(train_df[\"target\"][50])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deputies: Man shot before Brighton home set ablaze http://t.co/gWNRhMSO8k\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzthWrc6zjf1"
      },
      "source": [
        "# we can see that 1 is for disaster and 0 is for not disaster."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npER7NdWzptj"
      },
      "source": [
        "# Lets shuffle the data as we can see the df has a lot of 1s in the beginning."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDYDBJIjz4Pr"
      },
      "source": [
        "train_df_shuffled = train_df.sample(frac = 1,random_state= 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "mQIO_iST0KcV",
        "outputId": "3db15800-7027-40f2-dc1a-7a25d72c709e"
      },
      "source": [
        "train_df_shuffled.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jah2Wk3S0Mzb",
        "outputId": "d54fd1c7-3def-44b3-9799-8f88ba997ec4"
      },
      "source": [
        "# Seeing how many disaster tweets and how many non-disaster tweets are there in the dataset\n",
        "\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnab_B5u0Xv-"
      },
      "source": [
        "# 0    4342\n",
        "# 1    3271\n",
        "\n",
        "# We can see we have more non-disaster tweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh3E_SMy06qi",
        "outputId": "d67dd90f-79a9-4abc-85f2-1f27a90a0064"
      },
      "source": [
        "len(train_df),len(test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXdGa2Cr087W",
        "outputId": "2e257e8f-6c3f-49c4-bd3f-ba5341aad378"
      },
      "source": [
        "# Seeing some random tweets\n",
        "\n",
        "import random\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  random_number = random.randint(0,len(train_df)-1)\n",
        "  tar = train_df[\"target\"][random_number]\n",
        "\n",
        "  print(\"---------------------------\")\n",
        "\n",
        "  if tar == 1:\n",
        "    print(\"Disaster\")\n",
        "  else:\n",
        "    print(\"Not a disaster\")\n",
        "\n",
        "  print(\"---------------------------\")\n",
        "\n",
        "  print(train_df[\"text\"][random_number])\n",
        "\n",
        "  print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------\n",
            "Not a disaster\n",
            "---------------------------\n",
            "I added a video to a @YouTube playlist http://t.co/aTCMrjzJTp Nicki Minaj - Up In Flames (Official Video)\n",
            "\n",
            "\n",
            "\n",
            "---------------------------\n",
            "Not a disaster\n",
            "---------------------------\n",
            "@kinkyconnors IM sorry for my meltdown last night lmao but I'm getting my tooth fixed Friday ??????????????????????????????????\n",
            "\n",
            "\n",
            "\n",
            "---------------------------\n",
            "Disaster\n",
            "---------------------------\n",
            "Madhya Pradesh Train Derailment: Village Youth Saved Many Lives\n",
            "\n",
            "\n",
            "\n",
            "---------------------------\n",
            "Disaster\n",
            "---------------------------\n",
            "Now that's what you call a batting collapse #theashes\n",
            "\n",
            "\n",
            "\n",
            "---------------------------\n",
            "Disaster\n",
            "---------------------------\n",
            "'Money can't buy happiness' is just a lie we tell poor people to keep them from rioting.\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za6CzmDV1odm"
      },
      "source": [
        "# Creating the training and validation sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentences,val_sentences,train_labels,val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                         train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                         test_size  = 0.1,\n",
        "                                                                         random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QFiABe44p6V",
        "outputId": "3e79f3f7-c0e9-4ab7-d78c-0d3453382df8"
      },
      "source": [
        "len(train_sentences),len(val_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORjqmjEg44wn",
        "outputId": "231b2a3d-5884-4c96-a376-e3cb63a2ad10"
      },
      "source": [
        "print(train_sentences[:5])\n",
        "print(train_labels[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['@mogacola @zamtriossu i screamed after hitting tweet'\n",
            " 'Imagine getting flattened by Kurt Zouma'\n",
            " '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....'\n",
            " \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\"\n",
            " 'Somehow find you and I collide http://t.co/Ee8RpOahPk']\n",
            "[0 0 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3_DhTmg4-fB"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH67_lbbrpmh"
      },
      "source": [
        "# JUST AN EXAMPLE OF TEXT VECTORIZER. MADE AGAIN LATER WITH RIGHT VLAUES\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=None,\n",
        "                                    standardize = \"lower_and_strip_punctuation\",\n",
        "                                    split = \"whitespace\",\n",
        "                                    ngrams = None,\n",
        "                                    output_mode = \"int\",\n",
        "                                    output_sequence_length = None,\n",
        "                                    pad_to_max_tokens=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYCWSor3seth",
        "outputId": "f0508bf6-f459-4663-af89-eee9082cd410"
      },
      "source": [
        "# Set max vocab length \n",
        "\n",
        "max_vocab_length = 10000\n",
        "\n",
        "# Find average length to set it as the max length \n",
        "\n",
        "max_length = round(sum(len(i.split()) for i in train_sentences)/len(train_sentences))\n",
        "\n",
        "print(max_length)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lVpA61ftvpE"
      },
      "source": [
        "# Making the text vectorizer\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens = max_vocab_length,\n",
        "                                    output_mode = \"int\",\n",
        "                                    output_sequence_length = max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2s3VyhPukXA"
      },
      "source": [
        "# Fit/Adapt the vectorizer\n",
        "\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XejDqP48uuyK",
        "outputId": "986f0ca9-d843-4b1a-ac39-cdcc4d990177"
      },
      "source": [
        "# Using the text_vectorizer on a random sentence\n",
        "\n",
        "# The text_vectorizers needs a list as input\n",
        "\n",
        "sample_sentence = \"The cyclone is heading towards Orissa.\"\n",
        "\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[   2,  582,    9, 2964, 3316,    1,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsTH4K3KvCSv"
      },
      "source": [
        "# We can see that the shape is 1,15  as the max length is set to 15\n",
        "\n",
        "# Since the sentence has only 7 words thus all other are 0."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbMc5A3nvQtO",
        "outputId": "7261c0c5-4e90-461c-8826-3dfdb2a2b2dc"
      },
      "source": [
        "# Seeing the vocabulary\n",
        "\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "\n",
        "words_in_vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'the',\n",
              " 'a',\n",
              " 'in',\n",
              " 'to',\n",
              " 'of',\n",
              " 'and',\n",
              " 'i',\n",
              " 'is',\n",
              " 'for',\n",
              " 'on',\n",
              " 'you',\n",
              " 'my',\n",
              " 'with',\n",
              " 'it',\n",
              " 'that',\n",
              " 'at',\n",
              " 'by',\n",
              " 'this',\n",
              " 'from',\n",
              " 'be',\n",
              " 'are',\n",
              " 'was',\n",
              " 'have',\n",
              " 'like',\n",
              " 'as',\n",
              " 'up',\n",
              " 'so',\n",
              " 'just',\n",
              " 'but',\n",
              " 'me',\n",
              " 'im',\n",
              " 'your',\n",
              " 'not',\n",
              " 'amp',\n",
              " 'out',\n",
              " 'its',\n",
              " 'will',\n",
              " 'an',\n",
              " 'no',\n",
              " 'has',\n",
              " 'fire',\n",
              " 'after',\n",
              " 'all',\n",
              " 'when',\n",
              " 'we',\n",
              " 'if',\n",
              " 'now',\n",
              " 'via',\n",
              " 'new',\n",
              " 'more',\n",
              " 'get',\n",
              " 'or',\n",
              " 'about',\n",
              " 'what',\n",
              " 'he',\n",
              " 'people',\n",
              " 'news',\n",
              " 'been',\n",
              " 'over',\n",
              " 'one',\n",
              " 'how',\n",
              " 'dont',\n",
              " 'they',\n",
              " 'who',\n",
              " 'into',\n",
              " 'were',\n",
              " 'do',\n",
              " 'us',\n",
              " '2',\n",
              " 'can',\n",
              " 'video',\n",
              " 'emergency',\n",
              " 'there',\n",
              " 'disaster',\n",
              " 'than',\n",
              " 'police',\n",
              " 'would',\n",
              " 'his',\n",
              " 'still',\n",
              " 'her',\n",
              " 'some',\n",
              " 'body',\n",
              " 'storm',\n",
              " 'crash',\n",
              " 'burning',\n",
              " 'suicide',\n",
              " 'back',\n",
              " 'man',\n",
              " 'california',\n",
              " 'why',\n",
              " 'time',\n",
              " 'them',\n",
              " 'had',\n",
              " 'buildings',\n",
              " 'rt',\n",
              " 'first',\n",
              " 'cant',\n",
              " 'see',\n",
              " 'got',\n",
              " 'day',\n",
              " 'off',\n",
              " 'our',\n",
              " 'going',\n",
              " 'nuclear',\n",
              " 'know',\n",
              " 'world',\n",
              " 'bomb',\n",
              " 'fires',\n",
              " 'love',\n",
              " 'killed',\n",
              " 'go',\n",
              " 'attack',\n",
              " 'youtube',\n",
              " 'dead',\n",
              " 'two',\n",
              " 'families',\n",
              " '3',\n",
              " 'train',\n",
              " 'full',\n",
              " 'being',\n",
              " 'war',\n",
              " 'many',\n",
              " 'today',\n",
              " 'think',\n",
              " 'only',\n",
              " 'car',\n",
              " 'accident',\n",
              " 'life',\n",
              " 'hiroshima',\n",
              " 'their',\n",
              " 'say',\n",
              " 'may',\n",
              " 'down',\n",
              " 'watch',\n",
              " 'good',\n",
              " 'could',\n",
              " 'want',\n",
              " 'last',\n",
              " 'here',\n",
              " 'years',\n",
              " 'u',\n",
              " 'then',\n",
              " 'make',\n",
              " 'did',\n",
              " 'wildfire',\n",
              " 'way',\n",
              " 'help',\n",
              " 'best',\n",
              " 'too',\n",
              " 'even',\n",
              " 'because',\n",
              " 'home',\n",
              " 'death',\n",
              " 'collapse',\n",
              " 'bombing',\n",
              " 'mass',\n",
              " 'him',\n",
              " 'black',\n",
              " 'am',\n",
              " 'those',\n",
              " 'need',\n",
              " 'fatal',\n",
              " 'army',\n",
              " 'another',\n",
              " 'work',\n",
              " 'take',\n",
              " 'should',\n",
              " 'really',\n",
              " 'please',\n",
              " 'mh370',\n",
              " 'youre',\n",
              " 'look',\n",
              " 'lol',\n",
              " 'hot',\n",
              " 'pm',\n",
              " 'legionnaires',\n",
              " '4',\n",
              " 'right',\n",
              " '5',\n",
              " 'let',\n",
              " 'city',\n",
              " 'year',\n",
              " 'wreck',\n",
              " 'school',\n",
              " 'northern',\n",
              " 'much',\n",
              " 'forest',\n",
              " 'bomber',\n",
              " 'water',\n",
              " 'she',\n",
              " 'never',\n",
              " 'read',\n",
              " 'latest',\n",
              " 'homes',\n",
              " 'great',\n",
              " 'every',\n",
              " '1',\n",
              " 'live',\n",
              " 'god',\n",
              " 'fear',\n",
              " 'any',\n",
              " '\\x89Û',\n",
              " 'under',\n",
              " 'said',\n",
              " 'old',\n",
              " 'floods',\n",
              " '2015',\n",
              " 'getting',\n",
              " 'atomic',\n",
              " 'while',\n",
              " 'top',\n",
              " 'obama',\n",
              " 'feel',\n",
              " 'thats',\n",
              " 'since',\n",
              " 'near',\n",
              " 'flames',\n",
              " 'ever',\n",
              " 'come',\n",
              " 'where',\n",
              " 'these',\n",
              " 'military',\n",
              " 'japan',\n",
              " 'found',\n",
              " 'content',\n",
              " 'ass',\n",
              " 'without',\n",
              " 'weather',\n",
              " 'most',\n",
              " 'flooding',\n",
              " 'flood',\n",
              " 'damage',\n",
              " 'which',\n",
              " 'shit',\n",
              " 's',\n",
              " 'hope',\n",
              " 'everyone',\n",
              " 'before',\n",
              " 'stop',\n",
              " 'plan',\n",
              " 'malaysia',\n",
              " 'injured',\n",
              " 'hit',\n",
              " 'evacuation',\n",
              " 'during',\n",
              " 'debris',\n",
              " 'cross',\n",
              " 'coming',\n",
              " 'wild',\n",
              " 'well',\n",
              " 'times',\n",
              " 'sinking',\n",
              " 'oil',\n",
              " 'fucking',\n",
              " 'check',\n",
              " 'cause',\n",
              " 'weapons',\n",
              " 'truck',\n",
              " 'food',\n",
              " 'bloody',\n",
              " 'always',\n",
              " 'weapon',\n",
              " 'theres',\n",
              " 'state',\n",
              " 'little',\n",
              " 'injuries',\n",
              " 'free',\n",
              " 'wounded',\n",
              " 'summer',\n",
              " 'smoke',\n",
              " 'severe',\n",
              " 'reddit',\n",
              " 'next',\n",
              " 'movie',\n",
              " 'ive',\n",
              " 'hes',\n",
              " 'fall',\n",
              " 'evacuate',\n",
              " 'confirmed',\n",
              " 'bad',\n",
              " 'again',\n",
              " 'thunderstorm',\n",
              " 'set',\n",
              " 'night',\n",
              " 'natural',\n",
              " 'looks',\n",
              " 'heat',\n",
              " 'face',\n",
              " 'earthquake',\n",
              " 'boy',\n",
              " 'whole',\n",
              " 'until',\n",
              " 'thunder',\n",
              " 'through',\n",
              " 'says',\n",
              " 'panic',\n",
              " 'outbreak',\n",
              " 'made',\n",
              " 'lightning',\n",
              " 'fatalities',\n",
              " 'family',\n",
              " 'explosion',\n",
              " 'end',\n",
              " 'destroy',\n",
              " 'derailment',\n",
              " 'air',\n",
              " 'w',\n",
              " 'terrorist',\n",
              " 'survive',\n",
              " 'screaming',\n",
              " 'saudi',\n",
              " 'refugees',\n",
              " 'rain',\n",
              " 'murder',\n",
              " 'loud',\n",
              " 'liked',\n",
              " 'house',\n",
              " 'gonna',\n",
              " 'failure',\n",
              " 'collided',\n",
              " 'bag',\n",
              " 'attacked',\n",
              " 'ambulance',\n",
              " '70',\n",
              " 'wind',\n",
              " 'services',\n",
              " 'save',\n",
              " 'report',\n",
              " 'migrants',\n",
              " 'head',\n",
              " 'explode',\n",
              " 'charged',\n",
              " 'change',\n",
              " 'big',\n",
              " 'also',\n",
              " 'wrecked',\n",
              " 'warning',\n",
              " 'update',\n",
              " 'run',\n",
              " 'rescuers',\n",
              " 'released',\n",
              " 'photo',\n",
              " 'massacre',\n",
              " 'injury',\n",
              " 'hurricane',\n",
              " 'high',\n",
              " 'hail',\n",
              " 'fuck',\n",
              " 'does',\n",
              " 'destroyed',\n",
              " 'bus',\n",
              " 'blood',\n",
              " '40',\n",
              " '\\x89ÛÒ',\n",
              " 'wreckage',\n",
              " 'violent',\n",
              " 'twister',\n",
              " 'trauma',\n",
              " 'tragedy',\n",
              " 'terrorism',\n",
              " 'survivors',\n",
              " 'survived',\n",
              " 'sinkhole',\n",
              " 'sandstorm',\n",
              " 'road',\n",
              " 'rioting',\n",
              " 'red',\n",
              " 'real',\n",
              " 'put',\n",
              " 'post',\n",
              " 'national',\n",
              " 'missing',\n",
              " 'landslide',\n",
              " 'keep',\n",
              " 'girl',\n",
              " 'drought',\n",
              " 'curfew',\n",
              " 'breaking',\n",
              " 'bags',\n",
              " 'white',\n",
              " 'twitter',\n",
              " 'tonight',\n",
              " 'structural',\n",
              " 'spill',\n",
              " 'service',\n",
              " 'screamed',\n",
              " 'rescued',\n",
              " 'rescue',\n",
              " 'phone',\n",
              " 'ok',\n",
              " 'oh',\n",
              " 'mosque',\n",
              " 'lives',\n",
              " 'horrible',\n",
              " 'harm',\n",
              " 'game',\n",
              " 'dust',\n",
              " 'destruction',\n",
              " 'deluge',\n",
              " 'deaths',\n",
              " 'crashed',\n",
              " 'cliff',\n",
              " 'catastrophe',\n",
              " 'boat',\n",
              " 'away',\n",
              " 'august',\n",
              " 'area',\n",
              " 'apocalypse',\n",
              " 'woman',\n",
              " 'whirlwind',\n",
              " 'traumatised',\n",
              " 'stock',\n",
              " 'saw',\n",
              " 'ruin',\n",
              " 'riot',\n",
              " 'quarantine',\n",
              " 'kills',\n",
              " 'island',\n",
              " 'investigators',\n",
              " 'ill',\n",
              " 'hostages',\n",
              " 'hazard',\n",
              " 'danger',\n",
              " 'call',\n",
              " '15',\n",
              " 'women',\n",
              " 'windstorm',\n",
              " 'things',\n",
              " 'suspect',\n",
              " 'show',\n",
              " 'reunion',\n",
              " 'quarantined',\n",
              " 'lava',\n",
              " 'heart',\n",
              " 'engulfed',\n",
              " 'detonate',\n",
              " 'crush',\n",
              " 'collapsed',\n",
              " 'came',\n",
              " 'better',\n",
              " 'battle',\n",
              " 'armageddon',\n",
              " 'airplane',\n",
              " 'against',\n",
              " 'affected',\n",
              " 'use',\n",
              " 'trapped',\n",
              " 'thank',\n",
              " 'sunk',\n",
              " 'story',\n",
              " 'send',\n",
              " 'part',\n",
              " 'other',\n",
              " 'must',\n",
              " 'mudslide',\n",
              " 'market',\n",
              " 'iran',\n",
              " 'famine',\n",
              " 'exploded',\n",
              " 'electrocuted',\n",
              " 'ebay',\n",
              " 'displaced',\n",
              " 'derailed',\n",
              " 'derail',\n",
              " 'burned',\n",
              " 'bombed',\n",
              " 'blown',\n",
              " 'baby',\n",
              " 'around',\n",
              " 'zone',\n",
              " 'wave',\n",
              " 'wanna',\n",
              " 'sure',\n",
              " 'someone',\n",
              " 'screams',\n",
              " 'razed',\n",
              " 'power',\n",
              " 'obliterated',\n",
              " 'long',\n",
              " 'land',\n",
              " 'hundreds',\n",
              " 'heard',\n",
              " 'group',\n",
              " 'flattened',\n",
              " 'drown',\n",
              " 'doing',\n",
              " 'care',\n",
              " 'bridge',\n",
              " 'bagging',\n",
              " '9',\n",
              " 'went',\n",
              " 'used',\n",
              " 'typhoon',\n",
              " 'trouble',\n",
              " 'tornado',\n",
              " 'thought',\n",
              " 'thing',\n",
              " 'river',\n",
              " 'responders',\n",
              " 'past',\n",
              " 'pandemonium',\n",
              " 'officials',\n",
              " 'meltdown',\n",
              " 'lot',\n",
              " 'least',\n",
              " 'inundated',\n",
              " 'id',\n",
              " 'hostage',\n",
              " 'hijacking',\n",
              " 'hazardous',\n",
              " 'goes',\n",
              " 'drowning',\n",
              " 'didnt',\n",
              " 'devastation',\n",
              " 'demolish',\n",
              " 'collide',\n",
              " 'casualties',\n",
              " 'calgary',\n",
              " 'bang',\n",
              " 'anniversary',\n",
              " 'yet',\n",
              " 'wounds',\n",
              " 'volcano',\n",
              " 'tsunami',\n",
              " 'sue',\n",
              " 'st',\n",
              " 'song',\n",
              " 'something',\n",
              " 'shoulder',\n",
              " 'security',\n",
              " 'prebreak',\n",
              " 'possible',\n",
              " 'pkk',\n",
              " 'panicking',\n",
              " 'obliteration',\n",
              " 'obliterate',\n",
              " 'murderer',\n",
              " 'minute',\n",
              " 'light',\n",
              " 'lets',\n",
              " 'kill',\n",
              " 'isis',\n",
              " 'india',\n",
              " 'hijacker',\n",
              " 'hellfire',\n",
              " 'government',\n",
              " 'few',\n",
              " 'evacuated',\n",
              " 'due',\n",
              " 'detonated',\n",
              " 'desolation',\n",
              " 'crushed',\n",
              " 'chemical',\n",
              " 'blew',\n",
              " 'blazing',\n",
              " 'blast',\n",
              " 'annihilated',\n",
              " 'airport',\n",
              " '6',\n",
              " 'week',\n",
              " 'upheaval',\n",
              " 'trying',\n",
              " 'three',\n",
              " 'thanks',\n",
              " 'sound',\n",
              " 'soon',\n",
              " 'sirens',\n",
              " 'rainstorm',\n",
              " 'plane',\n",
              " 'music',\n",
              " 'making',\n",
              " 'kids',\n",
              " 'issues',\n",
              " 'half',\n",
              " 'guys',\n",
              " 'fedex',\n",
              " 'done',\n",
              " 'died',\n",
              " 'detonation',\n",
              " 'days',\n",
              " 'cyclone',\n",
              " 'county',\n",
              " 'collision',\n",
              " 'caused',\n",
              " 'catastrophic',\n",
              " 'bleeding',\n",
              " 'beautiful',\n",
              " '8',\n",
              " 'words',\n",
              " 'very',\n",
              " 'traffic',\n",
              " 'south',\n",
              " 'remember',\n",
              " 'policy',\n",
              " 'place',\n",
              " 'nothing',\n",
              " 'north',\n",
              " 'mp',\n",
              " 'longer',\n",
              " 'left',\n",
              " 'israeli',\n",
              " 'hell',\n",
              " 'fun',\n",
              " 'drowned',\n",
              " 'demolished',\n",
              " 'cool',\n",
              " 'both',\n",
              " 'bioterror',\n",
              " 'believe',\n",
              " 'avalanche',\n",
              " 'arson',\n",
              " 'turkey',\n",
              " 'snowstorm',\n",
              " 'site',\n",
              " 'shot',\n",
              " 'shooting',\n",
              " 'pic',\n",
              " 'nowplaying',\n",
              " 'media',\n",
              " 'islam',\n",
              " 'inside',\n",
              " 'hijack',\n",
              " 'helicopter',\n",
              " 'fight',\n",
              " 'fatality',\n",
              " 'fan',\n",
              " 'electrocute',\n",
              " 'doesnt',\n",
              " 'building',\n",
              " 'brown',\n",
              " 'bc',\n",
              " 'actually',\n",
              " '16yr',\n",
              " 'yes',\n",
              " 'watching',\n",
              " 'wait',\n",
              " 'ur',\n",
              " 'tell',\n",
              " 'swallowed',\n",
              " 'seismic',\n",
              " 'second',\n",
              " 'rubble',\n",
              " 're\\x89Û',\n",
              " 'plans',\n",
              " 'men',\n",
              " 'memories',\n",
              " 'line',\n",
              " 'la',\n",
              " 'horror',\n",
              " 'health',\n",
              " 'having',\n",
              " 'find',\n",
              " 'eyewitness',\n",
              " 'deluged',\n",
              " 'children',\n",
              " 'bush',\n",
              " 'anything',\n",
              " 'already',\n",
              " 'almost',\n",
              " 'aircraft',\n",
              " 'yourself',\n",
              " 'yeah',\n",
              " 'whats',\n",
              " 'tomorrow',\n",
              " 'such',\n",
              " 'start',\n",
              " 'side',\n",
              " 'searching',\n",
              " 'saved',\n",
              " 'reactor',\n",
              " 'probably',\n",
              " 'play',\n",
              " 'person',\n",
              " 'peace',\n",
              " 'outside',\n",
              " 'officer',\n",
              " 'nearby',\n",
              " 'n',\n",
              " 'maybe',\n",
              " 'lost',\n",
              " 'literally',\n",
              " 'hours',\n",
              " 'hear',\n",
              " 'far',\n",
              " 'die',\n",
              " 'demolition',\n",
              " 'data',\n",
              " 'crews',\n",
              " 'conclusively',\n",
              " 'business',\n",
              " 'american',\n",
              " '20',\n",
              " '\\x89ÛÓ',\n",
              " 'west',\n",
              " 'waves',\n",
              " 'team',\n",
              " 'street',\n",
              " 'stay',\n",
              " 'soudelor',\n",
              " 'reuters',\n",
              " 'manslaughter',\n",
              " 'leather',\n",
              " 'job',\n",
              " 'history',\n",
              " 'hey',\n",
              " 'feeling',\n",
              " 'eyes',\n",
              " 'everything',\n",
              " 'declares',\n",
              " 'deal',\n",
              " 'casualty',\n",
              " 'bodies',\n",
              " 'amid',\n",
              " 'ablaze',\n",
              " '7',\n",
              " '50',\n",
              " '30',\n",
              " '12',\n",
              " 'youth',\n",
              " 'wont',\n",
              " 'wake',\n",
              " 'theyre',\n",
              " 'support',\n",
              " 'stretcher',\n",
              " 'same',\n",
              " 'rise',\n",
              " 'picking',\n",
              " 'photos',\n",
              " 'own',\n",
              " 'others',\n",
              " 'order',\n",
              " 'omg',\n",
              " 'okay',\n",
              " 'name',\n",
              " 'myself',\n",
              " 'money',\n",
              " 'makes',\n",
              " 'leave',\n",
              " 'lab',\n",
              " 'gt',\n",
              " 'gets',\n",
              " 'flag',\n",
              " 'desolate',\n",
              " 'crisis',\n",
              " 'center',\n",
              " 'book',\n",
              " 'blight',\n",
              " 'blaze',\n",
              " 'ago',\n",
              " 'abc',\n",
              " '11yearold',\n",
              " 'womens',\n",
              " 'typhoondevastated',\n",
              " 'tv',\n",
              " 'trench',\n",
              " 'trains',\n",
              " 'texas',\n",
              " 'space',\n",
              " 'siren',\n",
              " 'shes',\n",
              " 'self',\n",
              " 'saipan',\n",
              " 'reason',\n",
              " 'rd',\n",
              " 'pretty',\n",
              " 'pick',\n",
              " 'offensive',\n",
              " 'move',\n",
              " 'meek',\n",
              " 'major',\n",
              " 'm',\n",
              " 'low',\n",
              " 'lord',\n",
              " 'huge',\n",
              " 'hat',\n",
              " 'flash',\n",
              " 'feared',\n",
              " 'fast',\n",
              " 'effect',\n",
              " 'course',\n",
              " 'country',\n",
              " 'control',\n",
              " 'class',\n",
              " 'child',\n",
              " 'chance',\n",
              " 'caught',\n",
              " 'called',\n",
              " 'bioterrorism',\n",
              " 'bestnaijamade',\n",
              " 'become',\n",
              " 'bar',\n",
              " 'banned',\n",
              " 'ball',\n",
              " 'aug',\n",
              " 'annihilation',\n",
              " 'wrong',\n",
              " 'win',\n",
              " 'usa',\n",
              " 'united',\n",
              " 'town',\n",
              " 'totally',\n",
              " 'toddler',\n",
              " 'though',\n",
              " 'temple',\n",
              " 'taken',\n",
              " 'stand',\n",
              " 'spot',\n",
              " 'signs',\n",
              " 'ship',\n",
              " 'pakistan',\n",
              " 'online',\n",
              " 'level',\n",
              " 'ladies',\n",
              " 'jobs',\n",
              " 'isnt',\n",
              " 'happy',\n",
              " 'hailstorm',\n",
              " 'friends',\n",
              " 'disea',\n",
              " 'damn',\n",
              " 'couple',\n",
              " 'case',\n",
              " 'blue',\n",
              " 'bigger',\n",
              " 'america',\n",
              " 'across',\n",
              " '10',\n",
              " 'yours',\n",
              " 'village',\n",
              " 'try',\n",
              " 'transport',\n",
              " 'talk',\n",
              " 'seen',\n",
              " 'russian',\n",
              " 'radio',\n",
              " 'projected',\n",
              " 'once',\n",
              " 'official',\n",
              " 'needs',\n",
              " 'nearly',\n",
              " 'mount',\n",
              " 'might',\n",
              " 'mayhem',\n",
              " 'instead',\n",
              " 'hollywood',\n",
              " 'haha',\n",
              " 'guy',\n",
              " 'gun',\n",
              " 'green',\n",
              " 'front',\n",
              " 'finally',\n",
              " 'favorite',\n",
              " 'experts',\n",
              " 'entire',\n",
              " 'east',\n",
              " 'daily',\n",
              " 'crazy',\n",
              " 'computers',\n",
              " 'coaches',\n",
              " 'christian',\n",
              " 'china',\n",
              " 'blizzard',\n",
              " 'anyone',\n",
              " 'aint',\n",
              " 'action',\n",
              " '25',\n",
              " 'virgin',\n",
              " 'vehicle',\n",
              " 'truth',\n",
              " 'trust',\n",
              " 'takes',\n",
              " 't',\n",
              " 'star',\n",
              " 'sorry',\n",
              " 'running',\n",
              " 'refugio',\n",
              " 'reddits',\n",
              " 'poor',\n",
              " 'pain',\n",
              " 'mom',\n",
              " 'miners',\n",
              " 'marks',\n",
              " 'looking',\n",
              " 'knock',\n",
              " 'issued',\n",
              " 'insurance',\n",
              " 'ignition',\n",
              " 'houses',\n",
              " 'heavy',\n",
              " 'hate',\n",
              " 'hard',\n",
              " 'happened',\n",
              " 'global',\n",
              " 'giant',\n",
              " 'gbbo',\n",
              " 'flight',\n",
              " 'eye',\n",
              " 'emmerdale',\n",
              " 'driver',\n",
              " 'devastated',\n",
              " 'd',\n",
              " 'costlier',\n",
              " 'cnn',\n",
              " 'cars',\n",
              " 'camp',\n",
              " 'beach',\n",
              " 'arsonist',\n",
              " 'angry',\n",
              " 'alone',\n",
              " 'added',\n",
              " '05',\n",
              " 'york',\n",
              " 'wonder',\n",
              " 'uk',\n",
              " 'turn',\n",
              " 'taking',\n",
              " 'subreddits',\n",
              " 'sounds',\n",
              " 'scared',\n",
              " 'russia',\n",
              " 'rly',\n",
              " 'reports',\n",
              " 'ready',\n",
              " 'quiz',\n",
              " 'public',\n",
              " 'property',\n",
              " 'pradesh',\n",
              " 'ppl',\n",
              " 'playing',\n",
              " 'pay',\n",
              " 'parole',\n",
              " 'pamela',\n",
              " 'pakistani',\n",
              " 'outrage',\n",
              " 'niggas',\n",
              " 'nagasaki',\n",
              " 'myanmar',\n",
              " 'muslims',\n",
              " 'mop',\n",
              " 'madhya',\n",
              " 'mad',\n",
              " 'lmao',\n",
              " 'learn',\n",
              " 'large',\n",
              " 'govt',\n",
              " 'give',\n",
              " 'gems',\n",
              " 'gave',\n",
              " 'funtenna',\n",
              " 'fukushima',\n",
              " 'former',\n",
              " 'film',\n",
              " 'earth',\n",
              " 'drive',\n",
              " 'downtown',\n",
              " 'dog',\n",
              " 'comes',\n",
              " 'closed',\n",
              " 'cake',\n",
              " 'british',\n",
              " 'bring',\n",
              " 'bbc',\n",
              " 'b',\n",
              " 'appears',\n",
              " 'aftershock',\n",
              " '13',\n",
              " '11',\n",
              " 'young',\n",
              " 'wow',\n",
              " 'worst',\n",
              " 'waving',\n",
              " 'washington',\n",
              " 'wanted',\n",
              " 'vs',\n",
              " 'view',\n",
              " 'upon',\n",
              " 'tweet',\n",
              " 'tree',\n",
              " 'tote',\n",
              " 'thousands',\n",
              " 'thinking',\n",
              " 'theater',\n",
              " 'soul',\n",
              " 'sky',\n",
              " 'sign',\n",
              " 'shows',\n",
              " 'shift',\n",
              " 'seeing',\n",
              " 'sea',\n",
              " 'scene',\n",
              " 'safety',\n",
              " 'rules',\n",
              " 'rock',\n",
              " 'reported',\n",
              " 'r',\n",
              " 'pray',\n",
              " 'playlist',\n",
              " 'patience',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH3oZHXtvbSX",
        "outputId": "31a4da7b-9063-4f40-a0cb-50b0ce871a21"
      },
      "source": [
        "# number of words in vocalbulary\n",
        "\n",
        "len(words_in_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y6bBKFKvkFM"
      },
      "source": [
        "# It was expected to be 10000 as we set the max size of vocabulary as well."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0ILyocVvpyw",
        "outputId": "05261bdb-c438-4d61-a346-dce02b96de91"
      },
      "source": [
        "# Top 5 words and last 5v words\n",
        "\n",
        "print(words_in_vocab[:5])\n",
        "\n",
        "print()\n",
        "\n",
        "print(words_in_vocab[-5:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '[UNK]', 'the', 'a', 'in']\n",
            "\n",
            "['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEgzWhezvyWL"
      },
      "source": [
        "# We can see the most common words are spaces (\" \"), then [UNK] which were the punctuations,etc. Then \"the\",\"a,\"in\" and other such words.\n",
        "\n",
        "# The least common words are pages, paeds, pads,padres,etc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyJOmPDXwKpg"
      },
      "source": [
        "##### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RTsk1VVwMlN"
      },
      "source": [
        "embedding = tf.keras.layers.Embedding(input_dim = max_vocab_length,\n",
        "                                      output_dim = 128,\n",
        "                                      input_length = max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHg57xAAwPXJ",
        "outputId": "a226733e-2a19-440d-b313-8589c102c8cc"
      },
      "source": [
        "embedding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7fde21d19910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXSHfT0Kwsvk",
        "outputId": "913a5699-2043-4e7a-b2e0-01c8842a235a"
      },
      "source": [
        "# Trying embedding on a random sentence.\n",
        "\n",
        "# the embedding requires a text_vectorizerized input\n",
        "\n",
        "\n",
        "sample_embed = embedding(text_vectorizer([sample_sentence]))\n",
        "\n",
        "sample_embed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 2.61947028e-02, -4.09372151e-05, -4.58424352e-02, ...,\n",
              "         -3.21570039e-02,  1.31714009e-02,  3.21646817e-02],\n",
              "        [ 8.75718519e-03,  4.92960475e-02, -2.43463404e-02, ...,\n",
              "         -1.01518035e-02, -6.99303299e-03, -2.37602834e-02],\n",
              "        [ 1.18264928e-02, -3.37104350e-02, -1.48755796e-02, ...,\n",
              "         -2.82621384e-02, -1.43779144e-02,  3.82083096e-02],\n",
              "        ...,\n",
              "        [-1.52111426e-02, -3.78493182e-02, -3.44001427e-02, ...,\n",
              "          1.30989589e-02,  8.08141381e-03, -1.84226148e-02],\n",
              "        [-1.52111426e-02, -3.78493182e-02, -3.44001427e-02, ...,\n",
              "          1.30989589e-02,  8.08141381e-03, -1.84226148e-02],\n",
              "        [-1.52111426e-02, -3.78493182e-02, -3.44001427e-02, ...,\n",
              "          1.30989589e-02,  8.08141381e-03, -1.84226148e-02]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuYrg9Pww_6f",
        "outputId": "4ab53c46-fb99-40d5-fa25-096f83e339aa"
      },
      "source": [
        "# Each int is described by 128 float numbers. This is done for each of the 15 int which were vectorized from a sentence."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([-0.01521114, -0.03784932, -0.03440014,  0.0467254 ,  0.02862969,\n",
              "       -0.01942397,  0.04052866,  0.04183784, -0.04519415,  0.01066961,\n",
              "        0.00096393,  0.04858148,  0.03935734, -0.03031158, -0.02807545,\n",
              "       -0.03609843, -0.00242481, -0.01969994,  0.04193461,  0.04157324,\n",
              "       -0.01551242,  0.02553216, -0.00747577, -0.00166125,  0.00314926,\n",
              "       -0.04937055,  0.03339041, -0.03579167,  0.03000417,  0.04695631,\n",
              "        0.04686364, -0.01749649,  0.03107666,  0.0028071 ,  0.03879431,\n",
              "       -0.02434716, -0.00592845,  0.01457116, -0.02398125,  0.02512806,\n",
              "       -0.00508202, -0.02397947, -0.04136392, -0.04320109,  0.02137304,\n",
              "        0.01202179,  0.02310315,  0.00550558, -0.02458713,  0.03099999,\n",
              "        0.04625131,  0.01729042,  0.02330125,  0.00631893,  0.02282475,\n",
              "        0.00988812, -0.04046027, -0.04254219, -0.04903687,  0.0388085 ,\n",
              "        0.00454953,  0.00651996,  0.00808054, -0.02310002, -0.02422491,\n",
              "       -0.01753629, -0.0402584 , -0.03599942,  0.02408543,  0.03470689,\n",
              "       -0.00809103, -0.04579028, -0.03720676,  0.01320853,  0.04355854,\n",
              "        0.01926804, -0.00263215,  0.03978393,  0.01676664,  0.01118211,\n",
              "       -0.04945061, -0.02776572, -0.02761379, -0.04070963, -0.04681014,\n",
              "        0.03765703,  0.04806774,  0.04419888, -0.01267102, -0.01943133,\n",
              "        0.01521634,  0.04775586, -0.00515831, -0.01317107, -0.00568571,\n",
              "       -0.03714941, -0.00136042, -0.0314296 ,  0.02488588,  0.01643432,\n",
              "       -0.03329679,  0.02048764, -0.03290786, -0.00365286, -0.00339456,\n",
              "       -0.04918936, -0.03120597, -0.01845485, -0.04868225, -0.03787594,\n",
              "       -0.00059275, -0.02792515, -0.02789596, -0.04257431, -0.00683421,\n",
              "       -0.04192896, -0.03473053, -0.0473303 , -0.03712254,  0.00510358,\n",
              "       -0.02860947, -0.02869561,  0.03271371,  0.01744659, -0.01240369,\n",
              "        0.01309896,  0.00808141, -0.01842261], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXgdACqExLCP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}